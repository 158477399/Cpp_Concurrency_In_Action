#第八章 并发代码设计

**本章主要内容**

- 线程间划分数据的技术<br>
- 影响并发代码性能的因素<br>
- 性能因素是如何影响数据结构的设计<br>
- 多线程代码中的异常安全<br>
- 可扩展性<br>
- 并行算法的实现<br>

之前章节中着重于介绍使用C++11中的新工具来写并发代码。在6、7章中我们了解到，如何使用这些工具来设计可以并发访问的基本数据结构。这就好比一个木匠不仅要知道如何做一个合页，或是一个组合柜，亦或一个桌子，并发的代码的使用，要比使用或设计基本数据结构多的多。这里需要将眼界放宽，所以需要构建更大的结构，进行高效的工作。我将使用已经多线程化的C++标准库算法作为例子，不过同样的原则也适用于对应用程序的扩展。

认真的思考如何进行并发化设计，对于每个编程项目来说都是很重要的。不过，在写多线程代码的时候，需要比写序列化代码考虑的因素多。不仅包括一般性因素，例如：封装，耦合和聚合(这些在很多软件设计书籍中，有很详细的介绍)，还要考虑哪些数据需要共享，如何同步访问数据，哪些线程需要等待哪些线程，等等。

在本章，我们将来关注这些问题，从高层(但也是基本的)考虑，如何使用线程，哪些代码应该在哪些线程上执行；以及，这将如何影响代码的清晰度，从底层细节上了解，如何构建共享数据来优化性能。

那么我们就先来看一下如何在线程间划分工作。

##8.1 线程间划分工作的技术

试想某时，你被要求负责建造一座房子。为了完成任务，你需要挖地基，砌墙，添加水暖，接入电线，等等。理论上，如果你很擅长建造屋子，那么这些事情都可以由你来完成，但是这样可能就要花费很长很长时间，并且需要不断的切换任务。或者，你可以雇佣一些人来帮助你完成房子的建造。那么现在你需要决定你要雇多少人，以及需要雇佣人员具有什么样的技能。比如，你可以雇几个人，这几个人什么都会。现在你还得不断的切换任务，不过因为雇佣了很多人，就要比之前完成的速度快很多。

或者，你可以雇佣一个包工队(专家组)，由瓦工，木匠，电工和水管工组成。你的包工队只做其精通的，所以当没有水暖任务时，水管工会喝着茶或咖啡，坐在那里休息。还是因为人多的缘故，要比之前一个人的速度快很多，并且水管工在收拾厕所的时候，电工可以将电线连接到厨房，不过当没有属于自己的任务时，有人就会休息。即使是有人在休息，你可能还是能感觉到雇佣包公队的方式，要比雇佣一群什么都会的人快。你的包工队不需要更换工具，并且每人对自己的任务可能要比都会的人做的快。是快还是慢，取决于特定的情况——你需要尝试，并且进行观察。

即使你雇佣包工队，你依旧可以选择拥有不同人数的团队。可能在一个团队中，瓦工的数量超过电工。同样，这会是一种补足，并且在建造不止一座房子的时候，会改变工作的整体效率。即使水管工没有太多的任务，在建造过一次房子后，你依旧能让他总是处于忙碌的状态。当包工队无事可做的时候，你是不会给他们钱的；即使每次工作只有那么几个人工作，你还需要负担整个团队的开销。

关于建造例子已经足够说明问题了；这些与线程所做的事情有什么关系呢？好吧，这些问题也会发生在线程上。你需要决定你要使用多少个线程，并且这些线程应该去做什么。还需要决定是使用“能工巧匠”的线程去完成所有的任务，还是使用“专业”线程只去完成一件事情，或将两种方法混合。在使用并发的时候，你需要作出诸多选择来驱动并发，这里的选择会决定代码的性能和清晰度。因此，这里的选择至关重要，所以可以在你设计应用程序的结构时，再作出适当的决定。在本节中，我们将看到很多划分任务的技术，那就先从线程间划分数据开始吧！

###8.1.1 在线程处理前对数据进行划分

最简单的并行算法，就是`std::for_each`的并行化，其会对一个数据集中每个元素执行同一个操作。为了并行化该算法，你可以为数据集中每个元素分配一个处理线程。如何划分才能获得最佳的性能，着很大程度上取决于数据结构实现的细节，在之后又关性能问题的章节会再提及此问题。

最简单的非配方式：为第一组N个元素分配一个线程，下一组N个元素再分配一个线程，以此类推，如图8.1所示。不管数据怎么分，每个线程都会对分配给它的元素进行操作，不过并不会和其他线程进行沟通，直到处理完成。

![](https://raw.githubusercontent.com/xiaoweiChen/Cpp_Concurrency_In_Action/master/images/chapter8/8-1.png)

图8.1 向线程分发连续的数据块

使用过MPI(*Message Passing Interface*)[1]和OpenMP[2]的人对这个结构一定很熟悉：一项任务被分割成多个，放入一个并行任务集中，执行线程独立的执行这些任务，并且结果在会有主线程中合并。这种方式在2.4节中的accumulate的例子中使用过了；在这个例子中，所有并行任务和主线程的任务都是累积和。对于for_each来说，主线程将无事可做，因为这个计算不需要最终处理。

最后一步对于并行程序来说十分重要；如清单2.8中那样原始的实现，最后一步就是一个串行的。不过，这一步同样也是能被并行化的；accumulate实际上是一个递减操作，所以清单2.8中，当线程数量大于一个线程上最小处理项的数目，可以对accumulate进行递归调用。或者，在工作线程就能像做一个完整的任务一样，对步骤进行递减，而非将每次都产生新的线程。

虽然这个技术十分强大，但是并不是哪里都适用。有时不能像之前那样，对任务进行整齐的划分，因为只有对数据进行处理后，才能进行明确的划分。这里特别适用了递归算法，就像快速排序；下面就来看看这种特别的方式。

###8.1.2 递归划分

快速排序有两个最基本的步骤：将数据划分到中枢元素之前或之后，然后对中枢元素之前和之后的两半数组再次进行快速排序。这里不能通过对数据的简单划分达到并行，因为，只有在一次排序结束后，才能知道哪些项在中枢元素之前和之后。当要对这种算法进行并行化，很自然的会想到使用递归。每一级的递归都会多次调用quick_sort函数，因为需要知道哪些元素在中枢元素之前和自后。递归调用是完全独立的，因为其访问的是不同的数据集，并且每次迭代都能并发执行。图8.2展示了这样的递归划分。

![](https://raw.githubusercontent.com/xiaoweiChen/Cpp_Concurrency_In_Action/master/images/chapter8/8-2.png)

图8.2 递归划分数据

在第4章中，已经见过这种实现。比起对大于和小于的数据块递归调用函数，使用`std::async()`可以对每一级的小于数据块进行同步。使用`std::async()`时，C++线程库就能决定何时让一个新线程执行任务，以及让其同步的执行任务。

很重要的是：当对一个很大的数据集进行排序时，当每层递归都产生一个新线程，最后就会产生大量的线程。你会看到其对性能的影响，如果有太多的线程存在，那么你的应用将会运行的很慢。如果数据集过于庞大，会将线程用完。那么在递归的基础上进行任务的划分，就是一个不错的注意；你只需要将一定数量的数据打包后，交给线程即可。`std::async()`可以出里这种简单的情况，不过其不是唯一的选择。

另一种选择是使用`std::thread::hardware_concurrency()`函数来确定线程的数量，就像在清单2.8中的并行版accumulate()一样。然后，比起每次递归调用启用一个新线程，你可以将已排序的数据推到线程安全的栈上，就像第6、7章中提及的。当线程无所事事，不是因为已经完成对自己数据块的梳理，就是因为在等待一组一排序数据产生，线程可以从栈上获取这组数据，并且对其排序。

下面的代码就是使用以上方式进行的实现

清单8.1 使用栈的并行快速排序算法——等待数据块排序
```c++
template<typename T>
struct sorter  // 1
{
  struct chunk_to_sort
  {
    std::list<T> data;
    std::promise<std::list<T> > promise;
  };

  thread_safe_stack<chunk_to_sort> chunks;  // 2
  std::vector<std::thread> threads;  // 3
  unsigned const max_thread_count;
  std::atomic<bool> end_of_data;

  sorter():
    max_thread_count(std::thread::hardware_concurrency()-1),
    end_of_data(false)
  {}

  ~sorter()  // 4
  {
    end_of_data=true;  // 5

    for(unsigned i=0;i<threads.size();++i)
    {
      threads[i].join();  // 6
    }
  }

  void try_sort_chunk()
  {
    boost::shared_ptr<chunk_to_sort > chunk=chunks.pop();  // 7
    if(chunk)
    {
      sort_chunk(chunk);  // 8
    }
  }

  std::list<T> do_sort(std::list<T>& chunk_data)  // 9
  {
    if(chunk_data.empty())
    {
      return chunk_data;
    }

    std::list<T> result;
    result.splice(result.begin(),chunk_data,chunk_data.begin());
    T const& partition_val=*result.begin();

    typename std::list<T>::iterator divide_point=  // 10
       std::partition(chunk_data.begin(),chunk_data.end(),
        [&](T const& val){return val<partition_val;});

    chunk_to_sort new_lower_chunk;
    new_lower_chunk.data.splice(new_lower_chunk.data.end(),
       chunk_data,chunk_data.begin(),
       divide_point);

    std::future<std::list<T> > new_lower=
      new_lower_chunk.promise.get_future();
    chunks.push(std::move(new_lower_chunk));  // 11
    if(threads.size()<max_thread_count)  // 12
    {
      threads.push_back(std::thread(&sorter<T>::sort_thread,this));
    }

    std::list<T> new_higher(do_sort(chunk_data));

    result.splice(result.end(),new_higher);
    while(new_lower.wait_for(std::chrono::seconds(0)) !=
       std::future_status::ready)  // 13
    {
      try_sort_chunk();  // 14
    }

    result.splice(result.begin(),new_lower.get());
    return result;
  }

  void sort_chunk(boost::shared_ptr<chunk_to_sort> const& chunk)
  {
    chunk->promise.set_value(do_sort(chunk->data));  // 15
  }

  void sort_thread()
  {
    while(!end_of_data)  // 16
    {
      try_sort_chunk();  // 17
      std::this_thread::yield();  // 18
    }
  }
};

template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input)  // 19
{
  if(input.empty())
  {
    return input;
  }
  sorter<T> s;

  return s.do_sort(input);  // 20
}
```

这里，parallel_quick_sort函数⑲代表了sorter类①的功能，其支持在栈上简单的存储无序数据块②，并且对线程进行设置③。do_sort成员函数⑨主要做的就是对数据进行划分⑩。相较于对每一个数据块产生一个新的线程，这次会将这些数据块推到栈上⑪；并在在有备用处理器⑫的时候，再产生新的线程。因为小于部分的数据块可能由其他线程进行处理，那么你就得等待这个线程完成⑬。为了让所有事情顺利进行(只有一个线程和其他所有线程都忙碌时)，当线程处于等待状态时⑭，就让本线程尝试处理栈上的数据。try_sort_chunk只是从栈上弹出一个数据块⑦，并且对其进行排序⑧，将结果存在promise中，让线程对已经存在于栈上的数据块进行提取⑮。

当end_of_data没有被设置时⑯，新生成的线程还在尝试从栈上获取需要排序的数据块⑰。在循环检查中，也要给其他线程机会⑱可以从栈上取下数据块进行更多的操作。这里的实现依赖sorter类④对线程的清理。当所有数据都已经排序完成，do_sort将会返回(即使还有工作线程在运行)，所以主线程将会从parallel_quick_sort⑳中返回，在这之后会销毁sorter对象。析构函数会设置end_of_data标志⑤，以及等待所有线程完成工作⑥。这里对标志的设置将终止线程函数内部的循环⑯。

这个方案中，就不用为spawn_task产生的无数线程所困扰，并且也不用再依赖C++线程库来为你选择执行线程的数量(就像`std::async()`那样)。该方案制约线程数量的值就是`std::thread::hardware_concurrency()`的值，这样就能避免任务过于频繁的切换了。不过这里还有一个问题：线程管理，以及线程间的通讯。要解决这两个问题就要增加代码的复杂程度。虽然线程对数据项是分开处理的，不过所有对栈的访问都能添加新的数据块到栈中，还有删除数据块以作处理。这里重度的竞争会降低性能，即使使用无锁(无阻塞)栈，原因将会在后面提到。

这个方案使用到了一个特别版的线程池——所有线程的任务都来源于一个等待链表，然后线程会去完成任务，完成任务后会再来链表提取任务。这个线程池很有问题(包括对工作链表的竞争)，这个问题的解决方案将在第9章提到。关于多处理器的问题，将会在本章后面的章节中有更为详细的讨论(详见8.2.1)。

几种划分方法：1，处理前划分；2，递归划分(都需要事先知道数据的长度固定)，还有上面的那种划分方式。事情并非总是这样好解决；当数据是动态生成，或是通过外部输入，那么这里的办法就不适用了。在这种情况下，基于任务类型对工作进行划分的方式，就要好于基于数据的划分方式。

###8.1.3 通过任务类型划分工作

##8.2 影响并发代码性能的因素

###8.2.1 有多少个处理器？

###8.2.2 数据争用与乒乓缓存

###8.2.3 伪共享

###8.2.4 如何接近数据？

###8.2.5 过载和频繁的任务切换

##8.3 为多线程性能设计数据结构

###8.3.1 为复杂操作划分数组元素

###8.3.2 其他数据结构中的数据访问模式

##8.4 设计并发代码的注意事项

###8.4.1 并行算法中的异常安全

###8.4.2 可扩展性和Amdahl定律

###8.4.3 使用多线程隐藏延迟

###8.4.4 使用并发提高响应能力

##8.5 在实践中设计并发代码

###8.5.1 并行实现：`std::for_each`

###8.5.2 并行实现：`std::find`

###8.5.3 并行实现：`std::partial_sum`

##8.6 小结


----------

【1】 http://www.mpi-forum.org/
【2】 http://www.openmp.org/